[
  {
    "objectID": "scripts/1_analyse_BN_truro.html",
    "href": "scripts/1_analyse_BN_truro.html",
    "title": "Load and Analyse Truro Network",
    "section": "",
    "text": "Load libraries\n\nlibrary(readxl)\nlibrary(Rgraphviz)\n\nLoading required package: graph\n\n\nLoading required package: BiocGenerics\n\n\n\nAttaching package: 'BiocGenerics'\n\n\nThe following objects are masked from 'package:stats':\n\n    IQR, mad, sd, var, xtabs\n\n\nThe following objects are masked from 'package:base':\n\n    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n    Position, rank, rbind, Reduce, rownames, sapply, saveRDS, setdiff,\n    table, tapply, union, unique, unsplit, which.max, which.min\n\n\nLoading required package: grid\n\nlibrary(bnlearn)\n\n\n\nRead in data\n\n# The path to data is relative to where the mrd file is located\nexcel_path &lt;- \"data/Markov_Blankets.xlsx\"\n# excel_path &lt;- \"/Users/imogenhobbs/Library/Mobile Documents/com~apple~CloudDocs/Theme 1 ResNet/MSc_Renewable_Resources/R/data/2Markov_Blankets.xlsx\"\n\n# Get all the sheet names\nsheet_vector &lt;- excel_sheets(excel_path)\n\n# Apply the read_excel function too all the sheets\ndat_list &lt;- mapply(FUN = read_excel, path =excel_path, \n                   sheet = sheet_vector)\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -&gt; `...1`\n\nnames(dat_list) &lt;- sheet_vector\n\n# Split the names of the sheets to get info on the variables\nsheet_vector_clean_split &lt;- \n  sapply(sheet_vector, function(x) { \n    if(grepl(\"and\", x)) strsplit(x, \"_and_\", fixed = T) else x})\n\nstr(dat_list)\n\nList of 9\n $ HD                        : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1       : chr [1:2] \"Expansion\" \"Return_to_Marshland\"\n  ..$ Probability: num [1:2] 0.1 0.9\n $ EW                        : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1       : chr [1:2] \"Above_Average_EW\" \"Below_Average_EW\"\n  ..$ Probability: num [1:2] 0.75 0.25\n $ FC                        : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1       : chr [1:2] \"Above_Average_FC\" \"Below_Average_FC\"\n  ..$ Probability: num [1:2] 0.1 0.9\n $ MAR                       : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1       : chr [1:2] \"Present_MAR\" \"Absent_MAR\"\n  ..$ Probability: num [1:2] 0.95 0.05\n $ DMK                       : tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1         : chr [1:2] \"High_DMK\" \"Low_DMK\"\n  ..$ Probabilities: num [1:2] 0.2 0.8\n $ IJ_and_HD                 : tibble [2 × 3] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1               : chr [1:2] \"Above_Average_IJ\" \"Below_Average_IJ\"\n  ..$ Expansion          : num [1:2] 0.7 0.3\n  ..$ Return_to_Marshland: num [1:2] 0.3 0.7\n $ TID_and_EW_and_MAR        : tibble [2 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1                        : chr [1:2] \"Above_Average_TID\" \"Below_Average_TID\"\n  ..$ Above_Average_EW:Present_MAR: num [1:2] 0.35 0.65\n  ..$ Below_Average_EW:Present_MAR: num [1:2] 0.2 0.8\n  ..$ Above_Average_EW:Absent_MAR : num [1:2] 0.45 0.55\n  ..$ Below_Average_EW:Absent_MAR : num [1:2] 0.3 0.7\n $ DMNT_and_FC_and_DMK       : tibble [2 × 5] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1                     : chr [1:2] \"Maintained\" \"Removed\"\n  ..$ Above_Average_FC:High_DMK: num [1:2] 0.3 0.7\n  ..$ Above_Average_FC:Low_DMK : num [1:2] 0.5 0.5\n  ..$ Below_Average_FC:High_DMK: num [1:2] 0.3 0.7\n  ..$ Below_Average_FC:Low_DMK : num [1:2] 0.6 0.4\n $ FL_and_IJ_and_TID_and_DMNT: tibble [2 × 9] (S3: tbl_df/tbl/data.frame)\n  ..$ ...1                                         : chr [1:2] \"Above_Average_FL\" \"Below_Average_FL\"\n  ..$ Above_Average_IJ:Above_Average_TID:Maintained: num [1:2] 0.4 0.6\n  ..$ Above_Average_IJ:Below_Average_TID:Maintained: num [1:2] 0.5 0.5\n  ..$ Below_Average_IJ:Above_Average_TID:Maintained: num [1:2] 0.5 0.5\n  ..$ Below_Average_IJ:Below_Average_TID:Maintained: num [1:2] 0.3 0.7\n  ..$ Above_Average_IJ:Above_Average_TID:Removed   : num [1:2] 0.5 0.5\n  ..$ Above_Average_IJ:Below_Average_TID:Removed   : num [1:2] 0.4 0.6\n  ..$ Below_Average_IJ:Above_Average_TID:Removed   : num [1:2] 0.4 0.6\n  ..$ Below_Average_IJ:Below_Average_TID:Removed   : num [1:2] 0.2 0.8\n\nprint(sheet_vector_clean_split)\n\n$HD\n[1] \"HD\"\n\n$EW\n[1] \"EW\"\n\n$FC\n[1] \"FC\"\n\n$MAR\n[1] \"MAR\"\n\n$DMK\n[1] \"DMK\"\n\n$IJ_and_HD\n[1] \"IJ\" \"HD\"\n\n$TID_and_EW_and_MAR\n[1] \"TID\" \"EW\"  \"MAR\"\n\n$DMNT_and_FC_and_DMK\n[1] \"DMNT\" \"FC\"   \"DMK\" \n\n$FL_and_IJ_and_TID_and_DMNT\n[1] \"FL\"   \"IJ\"   \"TID\"  \"DMNT\"\n\n\n\n\nWrangling data into CPTs\nWe want to transform the data into probability tables for bnlearn\n\ntables 1-: simple conversion to matrix with some cleaning steps\ntables 7-8: is 3 and 4-way so more wrangling is needed\n\n\nsource(\"scripts/0_functions.R\")\n\nWe apply the function clean_tables to all the sheets.\n\ncpt_list &lt;- mapply(FUN = clean_tables, \n                   tbl = dat_list, \n                   element_names = sheet_vector_clean_split)\nnames(cpt_list) &lt;- sapply(sheet_vector_clean_split, `[`, 1)\nprint(cpt_list)\n\n$HD\nHD\n          Expansion Return_to_Marshland \n                0.1                 0.9 \n\n$EW\nEW\nAbove_Average_EW Below_Average_EW \n            0.75             0.25 \n\n$FC\nFC\nAbove_Average_FC Below_Average_FC \n             0.1              0.9 \n\n$MAR\nMAR\nPresent_MAR  Absent_MAR \n       0.95        0.05 \n\n$DMK\nDMK\nHigh_DMK  Low_DMK \n     0.2      0.8 \n\n$IJ\n                  HD\nIJ                 Expansion Return_to_Marshland\n  Above_Average_IJ       0.7                 0.3\n  Below_Average_IJ       0.3                 0.7\n\n$TID\n, , MAR = Present_MAR\n\n                   EW\nTID                 Above_Average_EW Below_Average_EW\n  Above_Average_TID             0.35              0.2\n  Below_Average_TID             0.65              0.8\n\n, , MAR = Absent_MAR\n\n                   EW\nTID                 Above_Average_EW Below_Average_EW\n  Above_Average_TID             0.45              0.3\n  Below_Average_TID             0.55              0.7\n\n\n$DMNT\n, , DMK = High_DMK\n\n            FC\nDMNT         Above_Average_FC Below_Average_FC\n  Maintained              0.3              0.3\n  Removed                 0.7              0.7\n\n, , DMK = Low_DMK\n\n            FC\nDMNT         Above_Average_FC Below_Average_FC\n  Maintained              0.5              0.6\n  Removed                 0.5              0.4\n\n\n$FL\n, , TID = Above_Average_TID, DMNT = Maintained\n\n                  IJ\nFL                 Above_Average_IJ Below_Average_IJ\n  Above_Average_FL              0.4              0.5\n  Below_Average_FL              0.6              0.5\n\n, , TID = Below_Average_TID, DMNT = Maintained\n\n                  IJ\nFL                 Above_Average_IJ Below_Average_IJ\n  Above_Average_FL              0.5              0.3\n  Below_Average_FL              0.5              0.7\n\n, , TID = Above_Average_TID, DMNT = Removed\n\n                  IJ\nFL                 Above_Average_IJ Below_Average_IJ\n  Above_Average_FL              0.5              0.4\n  Below_Average_FL              0.5              0.6\n\n, , TID = Below_Average_TID, DMNT = Removed\n\n                  IJ\nFL                 Above_Average_IJ Below_Average_IJ\n  Above_Average_FL              0.4              0.2\n  Below_Average_FL              0.6              0.8\n\n\n\n\nCreating the network\nWe create the network with a string of symbols (see Scutari).\n\nnetwork &lt;- (model2network(\"[HD][MAR][IJ|HD][EW][TID|MAR:EW][FC][DMK][DMNT|FC:DMK][FL|IJ:TID:DMNT]\"))\ngraphviz.plot(network)\n\n\n\n\n\n\n\n\n\n\nFitting\nWe can now fit the network:\n\nbn &lt;- bnlearn::custom.fit(network, cpt_list)\nprint(bn)\n\n\n  Bayesian network parameters\n\n  Parameters of node DMK (multinomial distribution)\n\nConditional probability table:\n DMK\nHigh_DMK  Low_DMK \n     0.2      0.8 \n\n  Parameters of node DMNT (multinomial distribution)\n\nConditional probability table:\n \n, , FC = Above_Average_FC\n\n            DMK\nDMNT         High_DMK Low_DMK\n  Maintained      0.3     0.5\n  Removed         0.7     0.5\n\n, , FC = Below_Average_FC\n\n            DMK\nDMNT         High_DMK Low_DMK\n  Maintained      0.3     0.6\n  Removed         0.7     0.4\n\n\n  Parameters of node EW (multinomial distribution)\n\nConditional probability table:\n EW\nAbove_Average_EW Below_Average_EW \n            0.75             0.25 \n\n  Parameters of node FC (multinomial distribution)\n\nConditional probability table:\n FC\nAbove_Average_FC Below_Average_FC \n             0.1              0.9 \n\n  Parameters of node FL (multinomial distribution)\n\nConditional probability table:\n \n, , IJ = Above_Average_IJ, TID = Above_Average_TID\n\n                  DMNT\nFL                 Maintained Removed\n  Above_Average_FL        0.4     0.5\n  Below_Average_FL        0.6     0.5\n\n, , IJ = Below_Average_IJ, TID = Above_Average_TID\n\n                  DMNT\nFL                 Maintained Removed\n  Above_Average_FL        0.5     0.4\n  Below_Average_FL        0.5     0.6\n\n, , IJ = Above_Average_IJ, TID = Below_Average_TID\n\n                  DMNT\nFL                 Maintained Removed\n  Above_Average_FL        0.5     0.4\n  Below_Average_FL        0.5     0.6\n\n, , IJ = Below_Average_IJ, TID = Below_Average_TID\n\n                  DMNT\nFL                 Maintained Removed\n  Above_Average_FL        0.3     0.2\n  Below_Average_FL        0.7     0.8\n\n\n  Parameters of node HD (multinomial distribution)\n\nConditional probability table:\n HD\n          Expansion Return_to_Marshland \n                0.1                 0.9 \n\n  Parameters of node IJ (multinomial distribution)\n\nConditional probability table:\n \n                  HD\nIJ                 Expansion Return_to_Marshland\n  Above_Average_IJ       0.7                 0.3\n  Below_Average_IJ       0.3                 0.7\n\n  Parameters of node MAR (multinomial distribution)\n\nConditional probability table:\n MAR\nPresent_MAR  Absent_MAR \n       0.95        0.05 \n\n  Parameters of node TID (multinomial distribution)\n\nConditional probability table:\n \n, , MAR = Present_MAR\n\n                   EW\nTID                 Above_Average_EW Below_Average_EW\n  Above_Average_TID             0.35             0.20\n  Below_Average_TID             0.65             0.80\n\n, , MAR = Absent_MAR\n\n                   EW\nTID                 Above_Average_EW Below_Average_EW\n  Above_Average_TID             0.45             0.30\n  Below_Average_TID             0.55             0.70\n\n\n\n\nBelief Propagation\nIn order to use this network to help make decisions about future events, we need to use Belief Propagation. Belief Propagation can be done with Exact or Approximate Algorithms. Because this network is small (among other reasons), we are going to use an Exact Algorithm with Junction Trees. Junction Trees are are popular method of exact inference and exist in the gRain package.\nJunction Trees require that the network be moralised, that is, an undirected graph, where each node is now connected to its Markov Blanket.\nLet’s moralise our BN:\n\ngraphviz.plot(moral(network))\n\n\n\n\n\n\n\n\nFrom this moral graph, we can isolate 4 Cliques: C1 = {DMK, FC, DMNT} C2 = {DMNT,TID, IJ} C3 = {TID, IJ, FL} C4 = {DMNT, IJ, FL}\nAnd 3 Separators: S12 = {DMNT} S14= {DMNT} S23 = {TID, IJ}\nThe following section has quotes from Oxford Bayesian Analysis by Scutari (2017).\nLet’s say we want to see what happens to the distribution of Tides (TID) and Ice Jams (IJ) given the evidence that DMNT is “Low.”\n“First, we convert the BN from bnlearn to its equivalent in gRain with as.grain() and we construct the junction tree with compile()”\n\nlibrary(gRain)\n\nLoading required package: gRbase\n\n\n\nAttaching package: 'gRbase'\n\n\nThe following objects are masked from 'package:bnlearn':\n\n    ancestors, children, nodes, parents\n\n\nThe following objects are masked from 'package:graph':\n\n    addEdge, adj, connComp, edges, nodes, removeEdge, subGraph\n\njunction &lt;- compile(as.grain(bn))\n\n“Then, we set the evidence to on the node,” in this case, fixing it to Low, “with probability 1 with setEvidence()”\n\njDMNT &lt;- setEvidence(junction, nodes = \"DMNT\", states = \"High\")\n\n“And after that, we can perform our conditional probability query with querygrain(), which also takes care of the belief propagation.”\n\nTIDxIJ.cpt &lt;- querygrain(jDMNT, nodes = c(\"TID\", \"IJ\"), type = \"joint\")\nprint(TIDxIJ.cpt)\n\n                  TID\nIJ                 Above_Average_TID Below_Average_TID\n  Above_Average_IJ           0.10795           0.23205\n  Below_Average_IJ           0.20955           0.45045\n\n\nLet’s try it with Flood-risk (FL), with the evidence being set on different variables:\n\nDecision maker knowledge:\n\n\njDMK &lt;- setEvidence(junction, nodes = \"DMK\", states = \"High_DMK\")\nFLxDMKcpt &lt;- querygrain(jDMK, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxDMKcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.34             0.66 \n\njDMK2 &lt;- setEvidence(junction, nodes = \"DMK\", states = \"Low_DMK\")\nFLxDMKcpt2 &lt;- querygrain(jDMK2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxDMKcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.37             0.63 \n\n\n\nHuman development:\n\n\njHD &lt;- setEvidence(junction, nodes = \"HD\", states = \"Expansion\")\nFLxHDcpt &lt;- querygrain(jHD, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxHDcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.41             0.59 \n\njHD2 &lt;- setEvidence(junction, nodes = \"HD\", states = \"Return_to_Marshland\")\nFLxHDcpt2 &lt;- querygrain(jHD2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxHDcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.36             0.64 \n\n\n\nDyke Maintenance\n\n\njDMNT &lt;- setEvidence(junction, nodes = \"DMNT\", states = \"Maintained\")\nFLxDMNTcpt &lt;- querygrain(jDMNT, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxDMNTcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n             0.4              0.6 \n\njDMNT2 &lt;- setEvidence(junction, nodes = \"DMNT\", states = \"Removed\")\nFLxDMNTcpt2 &lt;- querygrain(jDMNT2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxDMNTcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.32             0.68 \n\n\n\nFinancial Constraints\n\n\njFC &lt;- setEvidence(junction, nodes = \"FC\", states = \"Above_Average_FC\")\nFLxFCcpt &lt;- querygrain(jFC, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxFCcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.36             0.64 \n\njFC2 &lt;-setEvidence(junction, nodes = \"FC\", states = \"Below_Average_FC\")\nFLxFCcpt2 &lt;- querygrain(jFC2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxFCcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.36             0.64 \n\n\n\nTide frequency\n\n\njTF &lt;- setEvidence(junction, nodes = \"TID\", states = \"Above_Average_TID\")\nFLxTFcpt &lt;- querygrain(jTF, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxTFcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.45             0.55 \n\njTF2 &lt;-setEvidence(junction, nodes = \"TID\", states = \"Below_Average_TID\")\nFLxTFcpt2 &lt;- querygrain(jTF2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxTFcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.32             0.68 \n\n\n\nSaltmarsh status\n\n\njMAR &lt;- setEvidence(junction, nodes = \"MAR\", states = \"Present_MAR\")\nFLxMARcpt &lt;- querygrain(jMAR, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxMARcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.36             0.64 \n\njMAR2 &lt;-setEvidence(junction, nodes = \"MAR\", states = \"Absent_MAR\")\nFLxMARcpt2 &lt;- querygrain(jMAR2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxMARcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.37             0.63 \n\n\n\nExtreme weather frequency\n\n\njEW &lt;- setEvidence(junction, nodes = \"EW\", states = \"Above_Average_EW\")\nFLxEWcpt &lt;- querygrain(jEW, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxEWcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.37             0.63 \n\njEW2 &lt;-setEvidence(junction, nodes = \"EW\", states = \"Below_Average_EW\")\nFLxEWcpt2 &lt;- querygrain(jEW2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxEWcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.35             0.65 \n\n\n\nIce Jam frequency\n\n\njIJ &lt;- setEvidence(junction, nodes = \"IJ\", states = \"Above_Average_IJ\")\nFLxIJcpt &lt;- querygrain(jIJ, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxIJcpt, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.45             0.55 \n\njIJ2 &lt;- setEvidence(junction, nodes = \"IJ\", states = \"Below_Average_IJ\")\nFLxIJcpt2 &lt;- querygrain(jIJ2, nodes = c(\"FL\"), type = \"joint\")\nprint(round(FLxIJcpt2, 2))\n\nFL\nAbove_Average_FL Below_Average_FL \n            0.32             0.68 \n\n\n\n\nScenarios by permutations\n\nperms &lt;- gtools::permutations(2, 8, repeats.allowed = T)\nperms_list &lt;- lapply(apply(perms, MARGIN = 1, list), unlist)\n\ngraph_list &lt;- lapply(perms_list, FUN = generate_combination)\nFL &lt;- lapply(graph_list, function(x) c(querygrain(x, nodes = c(\"FL\"))[[1]])) \nscores &lt;- unlist(lapply(FL, function(x) x[2]))\nmax_ids &lt;- which(scores == max(scores))\npercent &lt;- (length(max_ids)/length(perms_list))*100\n\nbests &lt;- graph_list[max_ids]\n\n# &gt; length(bests)\n# [1] 32\n\nWe find that 32 scenarios maximize below average flood risk. Lets look at their evidence.\n\nevidences &lt;- lapply(bests, function(x) getEvidence(x))\nevidences_dfs &lt;- lapply(evidences, function(x){\n  df &lt;- as.data.frame(x)[, c(\"nodes\", \"hard_state\")]\n})\nall_evidence &lt;- dplyr::bind_rows(evidences_dfs)\n\nall_evidence_ar &lt;- as.data.frame(table(all_evidence)) |&gt; \n    dplyr::arrange(desc(Freq), nodes, decreasing = F)\n\nfiltered &lt;- all_evidence_ar |&gt; \n  dplyr::mutate(imp = Freq/length(bests)*100) |&gt; \n  dplyr::filter(Freq !=0)\n\nprint(filtered)\n\n   nodes          hard_state Freq imp\n1   DMNT             Removed   32 100\n2     IJ    Below_Average_IJ   32 100\n3    TID   Below_Average_TID   32 100\n4    DMK            High_DMK   16  50\n5    DMK             Low_DMK   16  50\n6     EW    Above_Average_EW   16  50\n7     EW    Below_Average_EW   16  50\n8     FC    Above_Average_FC   16  50\n9     FC    Below_Average_FC   16  50\n10    HD           Expansion   16  50\n11    HD Return_to_Marshland   16  50\n12   MAR          Absent_MAR   16  50\n13   MAR         Present_MAR   16  50"
  }
]